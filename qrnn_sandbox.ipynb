{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from collections import OrderedDict\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "%aimport qrnn\n",
    "\n",
    "theano.config.exception_verbosity='high'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hold options as static element in the opts class\n",
    "class opts():\n",
    "    hidden_size = 128\n",
    "    seq_len = 100        # Data sequence length\n",
    "    data_offset = 15     # Offset for every new input sequence\n",
    "    batch_size = 64\n",
    "    filter_width = 3     # Filter size to be used by QRNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size = 85; total data size = 6347705\n"
     ]
    }
   ],
   "source": [
    "dataset = 'shakespeare'\n",
    "data = open('data/' + dataset + '-compiled.txt', 'r').readlines()\n",
    "if dataset != 'music':\n",
    "    data = ''.join(data)\n",
    "    chars = list(set(data))\n",
    "else:\n",
    "    data = [list(x.strip().split(' ') + ['\\n']) for x in data]\n",
    "    data = [item for sublist in data for item in sublist]\n",
    "    chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print ('Vocabulary size = ' + str(vocab_size) + '; total data size = ' + str(data_size))\n",
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(data, b, b_size, seq_len, offset):\n",
    "    start = int(float(len(data))/float(b_size))\n",
    "    if start*(b_size - 1) + offset*b + seq_len >= len(data):\n",
    "        return None, None\n",
    "    X = np.zeros((b_size, seq_len, vocab_size), dtype=theano.config.floatX)\n",
    "    y = np.zeros((b_size, seq_len, vocab_size), dtype=np.int8)\n",
    "\n",
    "    for i in xrange(b_size):\n",
    "        c = start*i + offset*b\n",
    "        for j in xrange(seq_len):\n",
    "            X[i, j, char_to_ix[data[c]]] = 1.0\n",
    "            y[i, j, char_to_ix[data[c+1]]] = 1.0\n",
    "            c += 1\n",
    "\n",
    "    return X, y.reshape((b_size*seq_len, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_rnn_1(input_var, seq_len, dim, filter_width):\n",
    "    # ----- INPUT LAYER -----\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, seq_len, dim), input_var=input_var)\n",
    "    batch_size, _, _ = l_in.input_var.shape\n",
    "\n",
    "    # ----- LSTM LAYERS -----\n",
    "    l_rec = qrnn.QRNNLayer(l_in, seq_len, dim, opts.hidden_size, filter_width, pooling='fo')\n",
    "    l_rec = qrnn.QRNNLayer(l_rec, seq_len, opts.hidden_size, opts.hidden_size, filter_width, pooling='fo')\n",
    "    l_rec = qrnn.QRNNLayer(l_rec, seq_len, opts.hidden_size, opts.hidden_size, filter_width, pooling='fo')\n",
    "\n",
    "    # ----- FC LAYERS -----\n",
    "    l_reshape = lasagne.layers.ReshapeLayer(l_rec, (batch_size * seq_len, opts.hidden_size))\n",
    "    l_dense = lasagne.layers.DenseLayer(l_reshape, num_units=256,\n",
    "                                        nonlinearity=lasagne.nonlinearities.tanh)\n",
    "    l_dense = lasagne.layers.DenseLayer(l_dense, num_units=dim, nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "    return l_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(3333)\n",
    "lasagne.random.set_rng(np.random)\n",
    "\n",
    "# Create network and compiling functions\n",
    "print('Network creation and function compiling...')\n",
    "input_var = T.tensor3('inputs')\n",
    "output_var = T.bmatrix('outputs')\n",
    "s_var = T.iscalar('svar')\n",
    "\n",
    "network = build_rnn_1(input_var, opts.seq_len, vocab_size, opts.filter_width)\n",
    "network_output = lasagne.layers.get_output(network)\n",
    "loss = lasagne.objectives.categorical_crossentropy(network_output, output_var).mean()\n",
    "all_params = lasagne.layers.get_all_params(network)\n",
    "updates = lasagne.updates.adam(loss, all_params, learning_rate=0.001)\n",
    "\n",
    "# Perplexity\n",
    "no = network_output[s_var-1::s_var, :]\n",
    "theano_perplexity = theano.function([input_var, output_var, s_var], \n",
    "                                    T.sum(-T.log(T.sum(no * output_var, axis=1))), on_unused_input='ignore')\n",
    "\n",
    "train = theano.function(\n",
    "    [input_var, output_var],\n",
    "    loss, updates=updates, on_unused_input='ignore')\n",
    "\n",
    "sample = theano.function(\n",
    "    [input_var], network_output[-1, :], on_unused_input='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_params = None\n",
    "c = 0\n",
    "\n",
    "test_samples = 11200\n",
    "train_data = data[0:-test_samples]\n",
    "test_data = data[-test_samples:]\n",
    "\n",
    "# Train procedure\n",
    "print(\"Start training RNN...\")\n",
    "counter = 0\n",
    "printouts = [1, 3, 6, 13, 26, 51, 101, 201, 401, 801, 1601, 3201, 6401, 12801]\n",
    "max_counter = max(printouts)\n",
    "\n",
    "while True:\n",
    "    # Cyclic permutation of train set\n",
    "    splitpoint = np.random.randint(0, len(train_data))\n",
    "    train_data = train_data[splitpoint:] + train_data[:splitpoint]\n",
    "\n",
    "    cost = 0.0\n",
    "    b = 0.0\n",
    "    while True:\n",
    "        X, y = get_batch(train_data, int(b), opts.batch_size, opts.seq_len, opts.data_offset)\n",
    "        if X is None or y is None:\n",
    "            break\n",
    "        counter += 1\n",
    "        cost += train(X, y)\n",
    "\n",
    "        b += 1.0\n",
    "\n",
    "        if counter in printouts:\n",
    "            # THEANO PERPLEXITY\n",
    "            num, den = 0.0, 0.0\n",
    "            tb = 0\n",
    "            while True:\n",
    "                Xt, yt = get_batch(test_data, tb, opts.batch_size, 100, 1)\n",
    "                if Xt is None or yt is None:\n",
    "                    break\n",
    "                n2 = theano_perplexity(Xt, yt[100-1::100], 100)\n",
    "                d2 = opts.batch_size\n",
    "                num += n2\n",
    "                den += d2\n",
    "                tb += 1\n",
    "            print(str(counter) + ':' + str(np.exp(num / den)))\n",
    "\n",
    "            if counter >= max_counter:\n",
    "                break\n",
    "\n",
    "    if counter >= max_counter:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results QRNN model\n",
    "---\n",
    "3 stacked QRNN layers with filter width 3, dim 128 + dense 256 (sigmoid)\n",
    "\n",
    "<b>$f$-pooling</b><br />\n",
    "3201:7.02321607773<br />\n",
    "6401:5.58554180259<br />\n",
    "12801:4.91633971638<br />\n",
    "\n",
    "<b>$fo$-pooling</b><br />\n",
    "3201:6.48371135081<br />\n",
    "6401:5.2369685117<br />\n",
    "12801:4.42960824422<br />\n",
    "\n",
    "<b>$ifo$-pooling</b><br />\n",
    "3201:6.68349345005<br />\n",
    "6401:5.21300633551<br />\n",
    "12801:4.46497484423<br />\n",
    "\n",
    "With sigmoid nonlinearity at Z gate, we cannot get any lower than 5.95 (without regularization).<br />\n",
    "A linear nonlinearity at Z gate, results in 5.22.<br />\n",
    "All tanh nonlinearities doesn't go lower than 32.0!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_text(length=200):\n",
    "    # First take a random piece of bootstrap text\n",
    "    start = np.random.randint(0, len(test_data)-opts.seq_len)\n",
    "    s = test_data[start:start+opts.seq_len]\n",
    "    \n",
    "    # Convert to proper input data shape (here, batch size = 1)\n",
    "    s_np = np.zeros((1, opts.seq_len, vocab_size), dtype=theano.config.floatX)\n",
    "    for i in xrange(opts.seq_len):\n",
    "        s_np[0, i, char_to_ix[s[i]]] = 1.0\n",
    "    \n",
    "    # Start sampling loop\n",
    "    res = ''\n",
    "    for k in xrange(length):\n",
    "        # Predict next character\n",
    "        predict = sample(s_np)\n",
    "        predict_i = np.random.choice(range(vocab_size), p=predict.ravel())\n",
    "        res += ix_to_char[predict_i]\n",
    "        \n",
    "        # Update s_np\n",
    "        s_np[0, 0:-1, :] = s_np[0, 1:, :]\n",
    "        s_np[0, -1, :] = 0.0\n",
    "        s_np[0, -1, predict_i] = 1.0\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wear Arients!\n",
      "\n",
      "GLOUCESTER:\n",
      "But may for you have my plant.\n",
      "\n",
      "KING HENRY BOYDA:\n",
      "Nenton in thee, for I am is it,\n",
      "And save, I male shilt you with have charces, ruit\n",
      "To hear bets bring being againse?\n",
      "\n",
      "FROND\n"
     ]
    }
   ],
   "source": [
    "print(sample_text(length=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
